
# DEEP LEARNING BASED SPEECH EMOTION RECOGNITION USING MFCC IMAGES, DATA COMBINATION AND AUGMENTATION


Speech is one the most significant mode of communication among human beings, hence Speech processing has emerged as one of the important areas of research. Quantifiable identification of emotions using microphone sensors from voice signals is an emerging area of research for HCI in the field of healthcare, emergency call centers, depression detection, behavior evaluation, virtual reality, media recommendation, human-bot interaction, etc. Most of the research in this area has been done by training and evaluating the datasets in isolation and with limited features of speech. Also, one of the most challenging issues of SER is data scarcity. In our research, we try to combine voice samples from different datasets i.e., IEMOCAP, RAVDESS, EMODB, and SAVEE, to generate a larger corpus along with data augmentation and create a generalized deep learning-based model. Also, unlike most of the research, this research tries to use MFCC Images as an input, instead of limited MFCC hand-selected features, as it can provide complete information of speech and help in improving the model performance
